---
title: "Contagious Yawning in Dogs: Re-analysis (Part 1)"
author: Scott Claessens and Patrick Neilands
date: "`r format(Sys.Date())`"
output:
  html_document:
    df_print: paged
    toc: true
    number_sections: false
    toc_float: true
---

The purpose of this document is to re-analyse the data from six studies of contagious yawning in dogs. These studies are:

- [Joly-Mascheroni et al. (2008)](https://royalsocietypublishing.org/doi/abs/10.1098/rsbl.2008.0333)
- [O'Hara & Reeve (2011)](https://www.sciencedirect.com/science/article/pii/S0003347210004483)
- [Silva et al. (2012)](https://link.springer.com/article/10.1007/s10071-012-0473-2)
- [Madsen & Persson (2013)](https://link.springer.com/article/10.1007/s10071-012-0568-9)
- [Romero et al. (2013)](https://journals.plos.org/plosone/article?id=10.1371/journal.pone.0071365)
- [Buttner & Strasser (2014)](https://link.springer.com/article/10.1007/s10071-013-0641-z)

We would like to thank the authors of these studies for kindly sharing their original data with us.

# 0. Setup

```{r echo=FALSE, cache=FALSE, include=FALSE}
options(width = 120)

library(tidyverse)
library(brms)
library(tidybayes)
library(bayesplot)
library(brmstools)
library(ggpubr)
library(ggridges)
library(grid)
library(gtable)
library(cowplot)
```

Load the data.

```{r}
d <- 
  read.csv('data/yawnReanalysis.csv') %>%
  as_tibble() %>%
  # create dummy variables for re-analysis
  mutate(condition    = ifelse(condition == "Control", 0, 1),
         familiar     = ifelse(familiar  == "Unfamiliar", 0, 1),
         type         = ifelse(type == "Shelter", 0, 1),
         presentation = ifelse(presentation == "A", 0, 1),
         live         = ifelse(live == "Recording", 0, 1),
         demonstrator = ifelse(demonstrator == "Human", 0, 1),
         male         = ifelse(gender == 'F', 0, 1))

d
```

Visualise the outcome.

```{r message=F, warning=F, echo=F}
d %>%
  ggplot(aes(x = numberYawns)) +
  geom_histogram(binwidth = 0.5) +
  labs(x = 'Number of yawns')
```

And split by study.

```{r message=F, warning=F, echo=F}
d %>%
  ggplot(aes(x = numberYawns)) +
  geom_histogram(binwidth = 0.5) +
  labs(x = 'Number of yawns') +
  facet_wrap(.~study)
```

These look zero-inflated. A zero-inflated Poisson model follows the general form

$$
\begin{eqnarray}
y_i & \sim & \text{ZIPoisson} (p_i, \lambda_i)\\
\text{logit} (p_i) & = & \alpha_p  + \beta_p x_i \\
\text{log} (\lambda_i) & = & \alpha_\lambda + \text{log(offset)} + \beta_\lambda x_i
\end{eqnarray}
$$

where $p_i$ is the zero-inflation probability (so $1 - p_i$ is the probability of the process getting started). $\text{log(offset)}$ is the log of the exposure length, and simple algebra means that $\lambda_i$ is now the expected *rate* per exposure length, rather than the count.

To ensure that this class of model is the best fit to the data, we also run other classes of models (such as Poisson, hurdle Poisson, negative binomial, hurdle negative binomial, and zero-inflated negative binomial models) and compare using information criteria.

# 1. Fit zero-inflated Poisson models

## 1.1. Intercept-only model

We utlise a Bayesian multilevel modelling approach here, including random effects for individual dogs nested within studies. Throughout, we use the same linear model to predict $\lambda_i$ (the rate of yawning) and $p_i$ (the probability of the yawning process never even getting started). The latter is called `zi` inside the model formula.

To begin, we fit an intercept-only model.

```{r echo=F, eval=F}
m1.1 <- brm(data = d, family = zero_inflated_poisson,
          bf(numberYawns ~ 0 + intercept + offset(log(secs)) + (0 + intercept | study/ID),
             zi ~ 0 + intercept + (0 + intercept | study/ID)),
          prior = c(prior(student_t(3, -2, 10), class = b, coef = "intercept"),
                    prior(logistic(0, 1), class = b, coef = "intercept", dpar = zi),
                    prior(student_t(3, 0, 0.5), class = sd, dpar = zi)),
          iter = 2000, warmup = 1000, chains = 4, cores = 4,
          control = list(adapt_delta = 0.999))

m1.1 <- add_criterion(m1.1, c("loo","waic"))

save(m1.1, file = 'models/m1.1.rda')
```

```{r echo=F}
load('models/m1.1.rda')
summary(m1.1)
```

What priors did we use?

```{r echo=F}
prior_summary(m1.1)
```

Let's interpret each parameter in turn. The zero-inflation parameter `zi` is -0.62. This is on the logit scale, so we need to calculate the inverse logit.

```{r}
post <- posterior_samples(m1.1)

1 - inv_logit_scaled(post$b_zi_intercept) %>% # prob of yawning process getting started
  median() %>%
  round(2)
```

The median probability of the yawning process getting started is 0.64.

Let's calculate the average yawning rate once the yawning process gets started.

```{r}
(exp(post$b_intercept) * 60) %>% # Yawning rate (per min)
  median() %>%
  round(2)
```

The dogs yawn 0.16 times a minute, on average.

```{r echo=F}
# cleanup
rm(post)
```

## 1.2. Condition-only model

Next, we add condition to the model, also as a random effect grouped by individual dogs nested within studies.

```{r echo=F, eval=F}
m1.2 <- brm(data = d, family = zero_inflated_poisson,
          bf(numberYawns ~ 0 + intercept + condition + offset(log(secs)) + 
               (0 + intercept + condition | study/ID),
             zi ~ 0 + intercept + condition + 
               (0 + intercept + condition | study/ID)),
          prior = c(prior(student_t(3, -2, 10), class = b, coef = "intercept"),
                    prior(normal(0, 1), class = b, coef = "condition"),
                    prior(logistic(0, 1), class = b, coef = "intercept", dpar = zi),
                    prior(normal(0, 1), class = b, coef = "condition", dpar = zi),
                    prior(student_t(3, 0, 0.5), class = sd, dpar = zi)),
          iter = 2000, warmup = 1000, chains = 4, cores = 4,
          control = list(adapt_delta = 0.999, max_treedepth = 15))

m1.2 <- add_criterion(m1.2, c("loo","waic"))

save(m1.2, file = 'models/m1.2.rda')
```

```{r echo=F}
load('models/m1.2.rda')
summary(m1.2)
```

What priors did we use?

```{r echo=F}
prior_summary(m1.2)
```

Get difference between conditions.

```{r}
post <- posterior_samples(m1.2)

# yawning rates (per minute)
cond1 <- exp(post$b_intercept) * 60
median(cond1) %>% round(2)

cond2 <- exp(post$b_intercept + post$b_condition) * 60
median(cond2) %>% round(2)

diff <- cond2 - cond1

# proportion of prob mass above zero
(sum(diff > 0) / length(diff)) %>% round(2)
```

Visualise effect of condition (we call it "Treatment" in our figures due to a comment from a reviewer).

```{r warning=F, message=F,echo=F}
inset <-
  tibble(
    diff  = (exp(post$b_intercept + post$b_condition) - 
               exp(post$b_intercept)) * 60
    ) %>%
  ggplot(aes(x = diff)) +
  geom_density(fill = "grey90") +
  geom_vline(xintercept = 0, linetype = "dashed") +
  xlab("difference") +
  xlim(c(-0.25,0.5)) +
  theme_classic() +
  theme(axis.line = element_blank(),
        axis.ticks = element_blank(),
        axis.text.y = element_blank(),
        axis.title.y = element_blank(),
        text = element_text(size = 9))

tibble(
  Control  = exp(post$b_intercept) * 60,
  Yawning  = exp(post$b_intercept + post$b_condition) * 60
  ) %>% 
  gather(Condition, yawns) %>%
  ggplot(aes(x = yawns, fill = Condition, colour = Condition)) +
  geom_density(alpha = 0.1) +
  xlab("Yawning rate (per min)") +
  xlim(c(0,0.6)) +
  theme_classic() +
  theme(axis.line = element_blank(),
        axis.ticks = element_blank(),
        axis.text.y = element_blank(),
        axis.title.y = element_blank(),
        axis.title.x = element_text(margin = margin(t = 10)),
        legend.title = element_blank()) +
  annotation_custom(ggplotGrob(inset), xmin = 0.3, xmax = 0.55,
                    ymin = 7, ymax = 15)
```

The effect of condition across studies.

```{r echo=F, message=F, warning=F, eval=F}
brmstools::forest(m1.2, grouping = "study", pars = "condition") +
  geom_vline(xintercept = 0, linetype = "dashed")
```

```{r echo=F, message=F, warning=F}
tibble(
  `Average`    = (exp(post$b_intercept + post$b_condition) - 
                    exp(post$b_intercept)) * 60,
  `BT et al.`  = (exp(post$b_intercept + post$`r_study[BT.et.al,intercept]` + 
                        post$b_condition + post$`r_study[BT.et.al,condition]`) - 
                    exp(post$b_intercept + post$`r_study[BT.et.al,intercept]`)) * 60,
  `JM et al.`  = (exp(post$b_intercept + post$`r_study[JM.et.al,intercept]` + 
                        post$b_condition + post$`r_study[JM.et.al,condition]`) - 
                    exp(post$b_intercept + post$`r_study[JM.et.al,intercept]`)) * 60,
  `MAD et al.` = (exp(post$b_intercept + post$`r_study[MAD.et.al,intercept]` + 
                        post$b_condition + post$`r_study[MAD.et.al,condition]`) - 
                    exp(post$b_intercept + post$`r_study[MAD.et.al,intercept]`)) * 60,
  `OHA et al.` = (exp(post$b_intercept + post$`r_study[OHA.et.al,intercept]` + 
                        post$b_condition + post$`r_study[OHA.et.al,condition]`) - 
                    exp(post$b_intercept + post$`r_study[OHA.et.al,intercept]`)) * 60,
  `ROM et al.` = (exp(post$b_intercept + post$`r_study[ROM.et.al,intercept]` + 
                        post$b_condition + post$`r_study[ROM.et.al,condition]`) - 
                    exp(post$b_intercept + post$`r_study[ROM.et.al,intercept]`)) * 60,
  `SIL et al.` = (exp(post$b_intercept + post$`r_study[SIL.et.al,intercept]` + 
                        post$b_condition + post$`r_study[SIL.et.al,condition]`) - 
                    exp(post$b_intercept + post$`r_study[SIL.et.al,intercept]`)) * 60
  ) %>%
  gather(study, samples) %>%
  
  ggplot(aes(x = samples, y = study)) +
  geom_density_ridges2(fill = "grey90") +
  geom_vline(xintercept = 0, linetype = "dashed") +
  annotate("text", x = 0.6, y = seq(1.4,7.4,by=1), label = c("0.95","0.38","0.99","0.99","0.99","0.99","0.98")) +
  annotate("text", x = 0.6, y = 8, label = "PPM") +
  xlim(c(-0.2,0.75)) +
  xlab("Difference in yawning rate (per min)\nbetween treatments") +
  coord_cartesian(clip = "off") +
  theme_classic() +
  theme(axis.line = element_blank(),
        axis.ticks = element_blank(),
        axis.title.y = element_blank(),
        axis.title.x = element_text(margin = margin(t = 10)))
```

BT et al. is the only study where the parameter crosses zero, and is also the largest study and the only one done entirely with shelter dogs. We should control for this later.

```{r echo=F}
# cleanup
rm(inset, post, cond1, cond2, diff)
```

## 1.3. Familiarity-only model

We replace condition with familiarity in the model, again as a random effect grouped by individual dogs nested within studies.

```{r echo=F, eval=F}
m1.3 <- brm(data = d, family = zero_inflated_poisson,
          bf(numberYawns ~ 0 + intercept + familiar + offset(log(secs)) + 
               (0 + intercept | study/ID),
             zi ~ 0 + intercept + familiar + 
               (0 + intercept | study/ID)),
          prior = c(prior(student_t(3, -2, 10), class = b, coef = "intercept"),
                    prior(normal(0, 1), class = b, coef = "familiar"),
                    prior(logistic(0, 1), class = b, coef = "intercept", dpar = zi),
                    prior(normal(0, 1), class = b, coef = "familiar", dpar = zi),
                    prior(student_t(3, 0, 0.5), class = sd, dpar = zi)),
          iter = 2000, warmup = 1000, chains = 4, cores = 4,
          control = list(adapt_delta = 0.999, max_treedepth = 15))

m1.3 <- add_criterion(m1.3, c("loo","waic"))

save(m1.3, file = 'models/m1.3.rda')
```

```{r echo=F}
load('models/m1.3.rda')
summary(m1.3)
```

What priors did we use?

```{r echo=F}
prior_summary(m1.3)
```

## 1.4. Condition + Familiarity model

We include both condition and familiarity as additive effects.

```{r echo=F, eval=F}
m1.4 <- brm(data = d, family = zero_inflated_poisson,
          bf(numberYawns ~ 0 + intercept + condition + familiar + offset(log(secs)) + 
               (0 + intercept + condition | study/ID),
             zi ~ 0 + intercept + condition + familiar + 
               (0 + intercept + condition | study/ID)),
          prior = c(prior(student_t(3, -2, 10), class = b, coef = "intercept"),
                    prior(normal(0, 1), class = b, coef = "condition"),
                    prior(normal(0, 1), class = b, coef = "familiar"),
                    prior(logistic(0, 1), class = b, coef = "intercept", dpar = zi),
                    prior(normal(0, 1), class = b, coef = "condition", dpar = zi),
                    prior(normal(0, 1), class = b, coef = "familiar", dpar = zi),
                    prior(student_t(3, 0, 0.5), class = sd, dpar = zi)),
          iter = 2000, warmup = 1000, chains = 4, cores = 4,
          control = list(adapt_delta = 0.999, max_treedepth = 15))

m1.4 <- add_criterion(m1.4, c("loo","waic"))

save(m1.4, file = 'models/m1.4.rda')
```

```{r echo=F}
load('models/m1.4.rda')
summary(m1.4)
```

What priors did we use?

```{r echo=F}
prior_summary(m1.4)
```

Get difference between conditions, controlling for familiarity.

```{r}
post <- posterior_samples(m1.4)

# yawning rates (per minute)
cond1 <- exp(post$b_intercept) * 60
median(cond1) %>% round(2)

cond2 <- exp(post$b_intercept + post$b_condition) * 60
median(cond2) %>% round(2)

diff <- cond2 - cond1

# proportion of prob mass above zero
(sum(diff > 0) / length(diff)) %>% round(2)
```

```{r echo=F}
# cleanup
rm(post, cond1, cond2, diff)
```

## 1.5. Condition*Familiarity model

Finally, we allow condition and familiarity to interact with one another.

```{r echo=F, eval=F}
m1.5 <- brm(data = d, family = zero_inflated_poisson,
          bf(numberYawns ~ 0 + intercept + condition*familiar + offset(log(secs)) + 
               (0 + intercept + condition | study/ID),
             zi ~ 0 + intercept + condition*familiar + 
               (0 + intercept + condition | study/ID)),
          prior = c(prior(student_t(3, -2, 10), class = b, coef = "intercept"),
                    prior(normal(0, 1), class = b, coef = "condition"),
                    prior(normal(0, 1), class = b, coef = "familiar"),
                    prior(normal(0, 1), class = b, coef = "condition:familiar"),
                    prior(logistic(0, 1), class = b, coef = "intercept", dpar = zi),
                    prior(normal(0, 1), class = b, coef = "condition", dpar = zi),
                    prior(normal(0, 1), class = b, coef = "familiar", dpar = zi),
                    prior(normal(0, 1), class = b, coef = "condition:familiar", dpar = zi),
                    prior(student_t(3, 0, 0.5), class = sd, dpar = zi)),
          iter = 3000, warmup = 1500, chains = 4, cores = 4,
          control = list(adapt_delta = 0.999, max_treedepth = 15))

m1.5 <- add_criterion(m1.5, c("loo","waic"))

save(m1.5, file = 'models/m1.5.rda')
```

```{r echo=F}
load('models/m1.5.rda')
summary(m1.5)
```

What priors did we use?

```{r echo=F}
prior_summary(m1.5)
```

Get yawning rate in each cell of 2x2 design.

```{r}
post <- posterior_samples(m1.5)

# yawning rates (per minute)
cond1unfam <- exp(post$b_intercept) * 60
cond2unfam <- exp(post$b_intercept + post$b_condition) * 60
cond1fam   <- exp(post$b_intercept + post$b_familiar) * 60
cond2fam   <- exp(post$b_intercept + post$b_condition + 
                    post$b_familiar + post$`b_condition:familiar`) * 60

median(cond1unfam) %>% round(2)
median(cond2unfam) %>% round(2)
median(cond1fam) %>% round(2)
median(cond2fam) %>% round(2)
```

Are there any differences in yawning rate? Get proportions of prob mass above zero for each contrast.

```{r}
diff1 <- cond2fam - cond1unfam
diff2 <- cond2fam - cond2unfam
diff3 <- cond2fam - cond1fam
diff4 <- cond1fam - cond1unfam
diff5 <- cond1fam - cond2unfam
diff6 <- cond2unfam - cond1unfam

(sum(diff1 > 0) / length(diff1)) %>% round(2)
(sum(diff2 > 0) / length(diff2)) %>% round(2)
(sum(diff3 > 0) / length(diff3)) %>% round(2)
(sum(diff4 > 0) / length(diff4)) %>% round(2)
(sum(diff5 > 0) / length(diff5)) %>% round(2)
(sum(diff6 > 0) / length(diff6)) %>% round(2)
```

Does the effect of condition differ between familiar and unfamiliar demonstrators? Interaction effect.

```{r}
(sum(diff3 - diff6 > 0) / length(diff3)) %>% round(2)
```

Visualise.

```{r warning=F, message=F, echo=F}
insetUnfamiliar <-
  tibble(
    diff  = (exp(post$b_intercept + post$b_condition) - exp(post$b_intercept)) * 60
    ) %>%
  ggplot(aes(x = diff)) +
  geom_density(fill = "grey90") +
  geom_vline(xintercept = 0, linetype = "dashed") +
  xlab("difference") +
  xlim(c(-0.25,0.5)) +
  theme_classic() +
  theme(axis.line = element_blank(),
        axis.ticks = element_blank(),
        axis.text.y = element_blank(),
        axis.title.y = element_blank(),
        text = element_text(size = 9))

insetFamiliar <-
  tibble(
    diff  = (exp(post$b_intercept + post$b_familiar + post$b_condition + post$`b_condition:familiar`) 
             - exp(post$b_intercept + post$b_familiar)) * 60
    ) %>%
  ggplot(aes(x = diff)) +
  geom_density(fill = "grey90") +
  geom_vline(xintercept = 0, linetype = "dashed") +
  xlab("difference") +
  xlim(c(-0.25,0.5)) +
  theme_classic() +
  theme(axis.line = element_blank(),
        axis.ticks = element_blank(),
        axis.text.y = element_blank(),
        axis.title.y = element_blank(),
        text = element_text(size = 9))

# custom function for inset plots inside facetted plots
annotation_custom2 <- function (grob, xmin = -Inf, xmax = Inf, ymin = -Inf, ymax = Inf, data) 
  {
    layer(data = data, stat = StatIdentity, position = PositionIdentity, 
          geom = ggplot2:::GeomCustomAnn,
          inherit.aes = TRUE, params = list(grob = grob, 
                                            xmin = xmin, xmax = xmax, 
                                            ymin = ymin, ymax = ymax))
  }

tibble(
  ControlUnfamiliar  = exp(post$b_intercept) * 60,
  YawningUnfamiliar  = exp(post$b_intercept + post$b_condition) * 60,
  ControlFamiliar    = exp(post$b_intercept + post$b_familiar) * 60,
  YawningFamiliar    = exp(post$b_intercept + post$b_condition 
                           + post$b_familiar + post$`b_condition:familiar`) * 60
  ) %>%
  gather(cell, yawns) %>%
  mutate(Condition   = rep(rep(c("Control", "Yawning"), each = 6000), times = 2),
         Familiarity = rep(c("Unfamiliar", "Familiar"), each = 12000)) %>%
  
  ggplot(aes(x = yawns, fill = Condition, colour = Condition)) +
  geom_density(alpha = 0.1) +
  xlab("Yawning rate (per min)") +
  xlim(c(0,0.6)) +
  facet_wrap(.~fct_rev(Familiarity)) +
  theme_classic() +
  theme(axis.line = element_blank(),
        axis.ticks = element_blank(),
        axis.text.y = element_blank(),
        axis.title.y = element_blank(),
        axis.title.x = element_text(margin = margin(t = 10)),
        legend.title = element_blank()) +
  annotation_custom2(ggplotGrob(insetFamiliar), 
                     data=data.frame(Familiarity="Familiar", Condition = NA, yawns = 1),
                     xmin=0.25, xmax=0.6, ymin=8, ymax=16) +
  annotation_custom2(ggplotGrob(insetUnfamiliar), 
                     data=data.frame(Familiarity="Unfamiliar", Condition = NA, yawns = 1),
                     xmin=0.25, xmax=0.6, ymin=8, ymax=16)
```

Let's compare all models so far.

```{r message=F, warning=F}
loo_compare(m1.1, m1.2, m1.3, m1.4, m1.5)
```

```{r echo=F, message=F, warning=F}
# visualise model comparison
looFig <-
  tibble(
    elpd_diff = c(loo_compare(m1.1, m1.2)[2]*-1,
                  loo_compare(m1.1, m1.3)[2]*-1,
                  loo_compare(m1.1, m1.4)[2]*-1,
                  loo_compare(m1.1, m1.5)[2]*-1,
                  loo_compare(m1.2, m1.3)[2],
                  loo_compare(m1.2, m1.4)[2]*-1,
                  loo_compare(m1.2, m1.5)[2]),
    se_diff = c(loo_compare(m1.1, m1.2)[4],
                  loo_compare(m1.1, m1.3)[4],
                  loo_compare(m1.1, m1.4)[4],
                  loo_compare(m1.1, m1.5)[4],
                  loo_compare(m1.2, m1.3)[4],
                  loo_compare(m1.2, m1.4)[4],
                  loo_compare(m1.2, m1.5)[4])
        ) %>%
  as.matrix() %>% as_tibble() %>% slice(1:7) %>%
  mutate(model = c("Treatment",
                   "Familiarity",
                   "Treatment+Familiarity",
                   "Treatment*Familiarity",
                   "Familiarity",
                   "Treatment+Familiarity",
                   "Treatment*Familiarity"))

looFig %>% slice(1:4) %>%
  ggplot(aes(x = fct_rev(factor(model, levels = model)), 
             y = elpd_diff, 
             ymin = elpd_diff - (se_diff*1.96), 
             ymax = elpd_diff + (se_diff*1.96))) +
  geom_pointrange(size = 0.35) +
  geom_hline(yintercept = 0, linetype = "dashed") +
  coord_flip() +
  xlab(NULL) +
  ylim(-50,50) +
  ylab("Difference in expected predictive accuracy\nfrom null model") +
  theme_classic()

looFig %>% slice(5:7) %>%
  ggplot(aes(x = fct_rev(factor(model, levels = model)), 
             y = elpd_diff, 
             ymin = elpd_diff - (se_diff*1.96), 
             ymax = elpd_diff + (se_diff*1.96))) +
  geom_pointrange(size = 0.35) +
  geom_hline(yintercept = 0, linetype = "dashed") +
  coord_flip() +
  xlab(NULL) +
  ylim(-50,50) +
  ylab("Difference in expected predictive accuracy\nfrom Treatment model") +
  theme_classic()
```

The best models are `m1.2`, `m1.4`, and `m1.5` - all the models that have a condition parameter. None of these models are substantially better than one another. This suggests that condition has an effect, but familiarity doesn't interact with it.

Going forward, we choose the condition-only model to continue analysing, as the most parsmionious model. Next, we add controls to see if the effect of condition is robust.

```{r echo=F}
# cleanup
rm(insetFamiliar, insetUnfamiliar, looFig,
   post, cond1fam, cond1unfam, cond2fam, cond2unfam,
   diff1, diff2, diff3, diff4, diff5, diff6)
```

## 1.6. Condition + Type model

We include both condition and type (shelter/pet) as additive effects.

```{r echo=F, eval=F}
m1.6 <- brm(data = d, family = zero_inflated_poisson,
          bf(numberYawns ~ 0 + intercept + condition + type + offset(log(secs)) + 
               (0 + intercept + condition | study/ID),
             zi ~ 0 + intercept + condition + type + 
               (0 + intercept + condition | study/ID)),
          prior = c(prior(student_t(3, -2, 10), class = b, coef = "intercept"),
                    prior(normal(0, 1), class = b, coef = "condition"),
                    prior(normal(0, 1), class = b, coef = "type"),
                    prior(logistic(0, 1), class = b, coef = "intercept", dpar = zi),
                    prior(normal(0, 1), class = b, coef = "condition", dpar = zi),
                    prior(normal(0, 1), class = b, coef = "type", dpar = zi),
                    prior(student_t(3, 0, 0.5), class = sd, dpar = zi)),
          iter = 3000, warmup = 1500, chains = 4, cores = 4,
          control = list(adapt_delta = 0.999, max_treedepth = 15))

m1.6 <- add_criterion(m1.6, c("loo","waic"))

save(m1.6, file = 'models/m1.6.rda')
```

```{r echo=F}
load('models/m1.6.rda')
summary(m1.6)
```

What priors did we use?

```{r echo=F}
prior_summary(m1.6)
```

Effect of condition?

```{r}
post <- posterior_samples(m1.6)
(sum(post$b_condition > 0) / length(post$b_condition)) %>% round(2)
```

Similar to before. Model comparison.

```{r message=F, warning=F}
loo_compare(m1.2, m1.6)
```

```{r echo=F}
# cleanup
rm(post)
```

## 1.7. Condition + Presentation model

```{r echo=F, eval=F}
m1.7 <- brm(data = d, family = zero_inflated_poisson,
          bf(numberYawns ~ 0 + intercept + condition + presentation + offset(log(secs)) + 
               (0 + intercept + condition | study/ID),
             zi ~ 0 + intercept + condition + presentation + 
               (0 + intercept + condition | study/ID)),
          prior = c(prior(student_t(3, -2, 10), class = b, coef = "intercept"),
                    prior(normal(0, 1), class = b, coef = "condition"),
                    prior(normal(0, 1), class = b, coef = "presentation"),
                    prior(logistic(0, 1), class = b, coef = "intercept", dpar = zi),
                    prior(normal(0, 1), class = b, coef = "condition", dpar = zi),
                    prior(normal(0, 1), class = b, coef = "presentation", dpar = zi),
                    prior(student_t(3, 0, 0.5), class = sd, dpar = zi)),
          iter = 2000, warmup = 1000, chains = 4, cores = 4,
          control = list(adapt_delta = 0.999, max_treedepth = 15))

m1.7 <- add_criterion(m1.7, c("loo","waic"))

save(m1.7, file = 'models/m1.7.rda')
```

```{r echo=F}
load('models/m1.7.rda')
summary(m1.7)
```

Priors.

```{r echo=F}
prior_summary(m1.7)
```

The effect of condition persists when controlling for presentation type (video and audio or audio-only).

```{r}
post <- posterior_samples(m1.7)
(sum(post$b_condition > 0) / length(post$b_condition)) %>% round(2)
```

Model comparison.

```{r message=F, warning=F}
loo_compare(m1.2, m1.7)
```

```{r echo=F}
# cleanup
rm(post)
```

## 1.8. Condition + Live model

```{r echo=F, eval=F}
m1.8 <- brm(data = d, family = zero_inflated_poisson,
          bf(numberYawns ~ 0 + intercept + condition + live + offset(log(secs)) + 
               (0 + intercept + condition | study/ID),
             zi ~ 0 + intercept + condition + live + 
               (0 + intercept + condition | study/ID)),
          prior = c(prior(student_t(3, -2, 10), class = b, coef = "intercept"),
                    prior(normal(0, 1), class = b, coef = "condition"),
                    prior(normal(0, 1), class = b, coef = "live"),
                    prior(logistic(0, 1), class = b, coef = "intercept", dpar = zi),
                    prior(normal(0, 1), class = b, coef = "condition", dpar = zi),
                    prior(normal(0, 1), class = b, coef = "live", dpar = zi),
                    prior(student_t(3, 0, 0.5), class = sd, dpar = zi)),
          iter = 2000, warmup = 1000, chains = 4, cores = 4,
          control = list(adapt_delta = 0.999, max_treedepth = 15))

m1.8 <- add_criterion(m1.8, c("loo","waic"))

save(m1.8, file = 'models/m1.8.rda')
```

```{r echo=F}
load('models/m1.8.rda')
summary(m1.8)
```

Priors.

```{r echo=F}
prior_summary(m1.8)
```

The effect of condition persists when controlling for whether the demonstration was live or recorded.

```{r}
post <- posterior_samples(m1.8)
(sum(post$b_condition > 0) / length(post$b_condition)) %>% round(2)
```

Model comparison.

```{r message=F, warning=F}
loo_compare(m1.2, m1.8)
```

```{r echo=F}
# cleanup
rm(post)
```

## 1.9. Condition + Demonstrator model

```{r echo=F, eval=F}
m1.9 <- brm(data = d, family = zero_inflated_poisson,
          bf(numberYawns ~ 0 + intercept + condition + demonstrator + offset(log(secs)) + 
               (0 + intercept + condition | study/ID),
             zi ~ 0 + intercept + condition + demonstrator + 
               (0 + intercept + condition | study/ID)),
          prior = c(prior(student_t(3, -2, 10), class = b, coef = "intercept"),
                    prior(normal(0, 1), class = b, coef = "condition"),
                    prior(normal(0, 1), class = b, coef = "demonstrator"),
                    prior(logistic(0, 1), class = b, coef = "intercept", dpar = zi),
                    prior(normal(0, 1), class = b, coef = "condition", dpar = zi),
                    prior(normal(0, 1), class = b, coef = "demonstrator", dpar = zi),
                    prior(student_t(3, 0, 0.5), class = sd, dpar = zi)),
          iter = 3000, warmup = 1500, chains = 4, cores = 4,
          control = list(adapt_delta = 0.999, max_treedepth = 15))

m1.9 <- add_criterion(m1.9, c("loo","waic"))

save(m1.9, file = 'models/m1.9.rda')
```

```{r echo=F}
load('models/m1.9.rda')
summary(m1.9)
```

Priors.

```{r echo=F}
prior_summary(m1.9)
```

The effect of condition persists.

```{r}
post <- posterior_samples(m1.9)
(sum(post$b_condition > 0) / length(post$b_condition)) %>% round(2)
```

Model comparison.

```{r message=F, warning=F}
loo_compare(m1.2, m1.9)
```

```{r echo=F}
# cleanup
rm(post)
```

## 1.10. Full model (all controls)

```{r echo=F, eval=F}
m1.10 <- brm(data = d, family = zero_inflated_poisson,
             bf(numberYawns ~ 0 + intercept + condition + presentation + type + 
                  demonstrator + familiar + live + offset(log(secs)) + 
                  (0 + intercept + condition | study/ID),
                zi ~ 0 + intercept + condition + presentation + type + 
                  demonstrator + familiar + live +
                  (0 + intercept + condition | study/ID)),
             prior = c(prior(student_t(3, -2, 10), class = b, coef = "intercept"),
                       prior(normal(0, 1), class = b, coef = "condition"),
                       prior(normal(0, 1), class = b, coef = "presentation"),
                       prior(normal(0, 1), class = b, coef = "type"),
                       prior(normal(0, 1), class = b, coef = "demonstrator"),
                       prior(normal(0, 1), class = b, coef = "familiar"),
                       prior(normal(0, 1), class = b, coef = "live"),
                       prior(logistic(0, 1), class = b, coef = "intercept", dpar = zi),
                       prior(normal(0, 1), class = b, coef = "condition", dpar = zi),
                       prior(normal(0, 1), class = b, coef = "presentation", dpar = zi),
                       prior(normal(0, 1), class = b, coef = "type", dpar = zi),
                       prior(normal(0, 1), class = b, coef = "demonstrator", dpar = zi),
                       prior(normal(0, 1), class = b, coef = "familiar", dpar = zi),
                       prior(normal(0, 1), class = b, coef = "live", dpar = zi),
                       prior(student_t(3, 0, 0.5), class = sd, dpar = zi)),
             iter = 3000, warmup = 1500, chains = 4, cores = 4,
             control = list(adapt_delta = 0.999, max_treedepth = 15))

m1.10 <- add_criterion(m1.10, c("loo","waic"))

save(m1.10, file = 'models/m1.10.rda')
```

```{r echo=F}
load('models/m1.10.rda')
summary(m1.10)
```

Priors.

```{r echo=F}
prior_summary(m1.10)
```

```{r}
post <- posterior_samples(m1.10)
(sum(post$b_condition > 0) / length(post$b_condition)) %>% round(2)
```

Model comparison.

```{r message=F, warning=F}
loo_compare(m1.2, m1.6, m1.7, m1.8, m1.9, m1.10)
```

```{r echo=F, message=F, warning=F}
# visualise model comparison
looFig <-
  tibble(
    elpd_diff = c(loo_compare(m1.2, m1.6)[2],
                  loo_compare(m1.2, m1.7)[2]*-1,
                  loo_compare(m1.2, m1.8)[2],
                  loo_compare(m1.2, m1.9)[2],
                  loo_compare(m1.2, m1.10)[2]),
    se_diff = c(loo_compare(m1.2, m1.6)[4],
                  loo_compare(m1.2, m1.7)[4],
                  loo_compare(m1.2, m1.8)[4],
                  loo_compare(m1.2, m1.9)[4],
                  loo_compare(m1.2, m1.10)[4])
        ) %>%
  as.matrix() %>% as_tibble() %>% slice(1:5) %>%
  mutate(model = c("Treatment+Type",
                   "Treatment+Presentation",
                   "Treatment+Live",
                   "Treatment+Demonstrator",
                   "Full model"))

looFig %>%
  ggplot(aes(x = fct_rev(factor(model, levels = model)), 
             y = elpd_diff, 
             ymin = elpd_diff - (se_diff*1.96), 
             ymax = elpd_diff + (se_diff*1.96))) +
  geom_pointrange(size = 0.35) +
  geom_hline(yintercept = 0, linetype = "dashed") +
  coord_flip() +
  xlab(NULL) +
  ylim(-8,8) +
  ylab("Difference in expected predictive accuracy\nfrom Treatment model") +
  theme_classic()
```

Plot condition parameter with controls.

```{r message=F, warning=F, echo=F}
tibble(
  `Treatment-only`           = ((exp(posterior_samples(m1.2)$b_intercept + posterior_samples(m1.2)$b_condition) - 
                                  exp(posterior_samples(m1.2)$b_intercept))*60)[1:4000],
  `Treatment + Type`         = ((exp(posterior_samples(m1.6)$b_intercept + posterior_samples(m1.6)$b_condition) - 
                                  exp(posterior_samples(m1.6)$b_intercept))*60)[1:4000],
  `Treatment + Presentation` = ((exp(posterior_samples(m1.7)$b_intercept + posterior_samples(m1.7)$b_condition) - 
                                  exp(posterior_samples(m1.7)$b_intercept))*60)[1:4000],
  `Treatment + Live`         = ((exp(posterior_samples(m1.8)$b_intercept + posterior_samples(m1.8)$b_condition) - 
                                  exp(posterior_samples(m1.8)$b_intercept))*60)[1:4000],
  `Treatment + Demonstrator` = ((exp(posterior_samples(m1.9)$b_intercept + posterior_samples(m1.9)$b_condition) - 
                                  exp(posterior_samples(m1.9)$b_intercept))*60)[1:4000],
  `Full model`               = ((exp(posterior_samples(m1.10)$b_intercept + posterior_samples(m1.10)$b_condition) - 
                                  exp(posterior_samples(m1.10)$b_intercept))*60)[1:4000]
) %>%
  gather(model, samples) %>%
  mutate(model = factor(model, levels = c("Treatment-only",
                                          "Treatment + Type",
                                          "Treatment + Presentation",
                                          "Treatment + Live",
                                          "Treatment + Demonstrator",
                                          "Full model"))) %>%
  
  ggplot(aes(x = samples, y = fct_rev(model))) +
  geom_density_ridges2(fill = "grey90", scale = 0.8) +
  geom_vline(xintercept = 0, linetype = "dashed") +
  annotate("text", x = 0.6, y = seq(1.4,6.4,by=1), label = c("0.93","0.94","0.94","0.95","0.94","0.95")) +
  annotate("text", x = 0.6, y = 7, label = "PPM") +
  xlim(c(-0.2,0.75)) +
  xlab("Difference in yawning rate (per min)\nbetween treatments") +
  coord_cartesian(clip = "off") +
  theme_classic() +
  theme(axis.line = element_blank(),
        axis.ticks = element_blank(),
        axis.title.y = element_blank(),
        axis.title.x = element_text(margin = margin(t = 10)))
```

```{r echo=F}
# cleanup
rm(post, looFig)
```

## 1.11. Gender-only model

```{r echo=F, eval=F}
m1.11 <- brm(data = d, family = zero_inflated_poisson,
             bf(numberYawns ~ 0 + intercept + male + offset(log(secs)) + 
                  (0 + intercept + male | study) + (0 + intercept | study:ID),
                zi ~ 0 + intercept + male + 
                  (0 + intercept + male | study) + (0 + intercept | study:ID)),
             prior = c(prior(student_t(3, -2, 10), class = b, coef = "intercept"),
                       prior(normal(0, 1), class = b, coef = "male"),
                       prior(logistic(0, 1), class = b, coef = "intercept", dpar = zi),
                       prior(normal(0, 1), class = b, coef = "male", dpar = zi),
                       prior(student_t(3, 0, 0.5), class = sd, dpar = zi)),
             iter = 2000, warmup = 1000, chains = 4, cores = 4,
             control = list(adapt_delta = 0.999, max_treedepth = 15))

m1.11 <- add_criterion(m1.11, c("loo","waic"))

save(m1.11, file = 'models/m1.11.rda')
```

```{r echo=F}
load('models/m1.11.rda')
summary(m1.11)
```

Priors.

```{r echo=F}
prior_summary(m1.11)
```

## 1.12. Condition + Gender model

```{r echo=F, eval=F}
m1.12 <- brm(data = d, family = zero_inflated_poisson,
             bf(numberYawns ~ 0 + intercept + condition + male + offset(log(secs)) + 
                  (0 + intercept + condition + male | study) +
                  (0 + intercept + condition | study:ID),
                zi ~ 0 + intercept + condition + male + 
                  (0 + intercept + condition + male | study) +
                  (0 + intercept + condition | study:ID)),
             prior = c(prior(student_t(3, -2, 10), class = b, coef = "intercept"),
                       prior(normal(0, 1), class = b, coef = "condition"),
                       prior(normal(0, 1), class = b, coef = "male"),
                       prior(logistic(0, 1), class = b, coef = "intercept", dpar = zi),
                       prior(normal(0, 1), class = b, coef = "condition", dpar = zi),
                       prior(normal(0, 1), class = b, coef = "male", dpar = zi),
                       prior(student_t(3, 0, 0.5), class = sd, dpar = zi)),
             iter = 2000, warmup = 1000, chains = 4, cores = 4,
             control = list(adapt_delta = 0.999, max_treedepth = 15))

m1.12 <- add_criterion(m1.12, c("loo","waic"))

save(m1.12, file = 'models/m1.12.rda')
```

```{r echo=F}
load('models/m1.12.rda')
summary(m1.12)
```

Priors.

```{r echo=F}
prior_summary(m1.12)
```

Get difference between conditions, controlling for gender.

```{r}
post <- posterior_samples(m1.12)

# yawning rates (per minute)
cond1 <- exp(post$b_intercept) * 60
median(cond1) %>% round(2)

cond2 <- exp(post$b_intercept + post$b_condition) * 60
median(cond2) %>% round(2)

diff <- cond2 - cond1

# proportion of prob mass above zero
(sum(diff > 0) / length(diff)) %>% round(2)
```

```{r echo=F}
# cleanup
rm(post, cond1, cond2, diff)
```

## 1.13. Condition*Gender model

```{r echo=F, eval=F}
m1.13 <- brm(data = d, family = zero_inflated_poisson,
             bf(numberYawns ~ 0 + intercept + condition*male + offset(log(secs)) + 
                  (0 + intercept + condition*male | study) +
                  (0 + intercept + condition | study:ID),
                zi ~ 0 + intercept + condition*male + 
                  (0 + intercept + condition*male | study) +
                  (0 + intercept + condition | study:ID)),
             prior = c(prior(student_t(3, -2, 10), class = b, coef = "intercept"),
                       prior(normal(0, 1), class = b, coef = "condition"),
                       prior(normal(0, 1), class = b, coef = "male"),
                       prior(normal(0, 1), class = b, coef = "condition:male"),
                       prior(logistic(0, 1), class = b, coef = "intercept", dpar = zi),
                       prior(normal(0, 1), class = b, coef = "condition", dpar = zi),
                       prior(normal(0, 1), class = b, coef = "male", dpar = zi),
                       prior(normal(0, 1), class = b, coef = "condition:male", dpar = zi),
                       prior(student_t(3, 0, 0.5), class = sd, dpar = zi)),
             iter = 2000, warmup = 1000, chains = 4, cores = 4,
             control = list(adapt_delta = 0.999, max_treedepth = 15))

m1.13 <- add_criterion(m1.13, c("loo","waic"))

save(m1.13, file = 'models/m1.13.rda')
```

```{r echo=F}
load('models/m1.13.rda')
summary(m1.13)
```

Priors.

```{r echo=F}
prior_summary(m1.13)
```

```{r}
post <- posterior_samples(m1.13)

# yawning rates (per minute)
cond1f <- exp(post$b_intercept) * 60
cond2f <- exp(post$b_intercept + post$b_condition) * 60
cond1m <- exp(post$b_intercept + post$b_male) * 60
cond2m <- exp(post$b_intercept + post$b_condition + 
                    post$b_male + post$`b_condition:male`) * 60

median(cond1f) %>% round(2)
median(cond2f) %>% round(2)
median(cond1m) %>% round(2)
median(cond2m) %>% round(2)
```

Are there any differences in yawning rate? Get proportions of prob mass above zero for each contrast.

```{r}
diff1 <- cond2m - cond1f
diff2 <- cond2m - cond2f
diff3 <- cond2m - cond1m
diff4 <- cond1m - cond1f
diff5 <- cond1m - cond2f
diff6 <- cond2f - cond1f

(sum(diff1 > 0) / length(diff1)) %>% round(2)
(sum(diff2 > 0) / length(diff2)) %>% round(2)
(sum(diff3 > 0) / length(diff3)) %>% round(2)
(sum(diff4 > 0) / length(diff4)) %>% round(2)
(sum(diff5 > 0) / length(diff5)) %>% round(2)
(sum(diff6 > 0) / length(diff6)) %>% round(2)
```

Does the effect of condition differ between males and females? Interaction effect.

```{r}
(sum(diff3 - diff6 > 0) / length(diff3)) %>% round(2)
```

Visualise.

```{r warning=F, message=F, echo=F}
insetFemale <-
  tibble(
    diff  = (exp(post$b_intercept + post$b_condition) - exp(post$b_intercept)) * 60
    ) %>%
  ggplot(aes(x = diff)) +
  geom_density(fill = "grey90") +
  geom_vline(xintercept = 0, linetype = "dashed") +
  xlab("difference") +
  xlim(c(-0.25,0.5)) +
  theme_classic() +
  theme(axis.line = element_blank(),
        axis.ticks = element_blank(),
        axis.text.y = element_blank(),
        axis.title.y = element_blank(),
        text = element_text(size = 9))

insetMale <-
  tibble(
    diff  = (exp(post$b_intercept + post$b_male + post$b_condition + post$`b_condition:male`) 
             - exp(post$b_intercept + post$b_male)) * 60
    ) %>%
  ggplot(aes(x = diff)) +
  geom_density(fill = "grey90") +
  geom_vline(xintercept = 0, linetype = "dashed") +
  xlab("difference") +
  xlim(c(-0.25,0.5)) +
  theme_classic() +
  theme(axis.line = element_blank(),
        axis.ticks = element_blank(),
        axis.text.y = element_blank(),
        axis.title.y = element_blank(),
        text = element_text(size = 9))


tibble(
  ControlFemale  = exp(post$b_intercept) * 60,
  YawningFemale  = exp(post$b_intercept + post$b_condition) * 60,
  ControlMale    = exp(post$b_intercept + post$b_male) * 60,
  YawningMale    = exp(post$b_intercept + post$b_condition 
                           + post$b_male + post$`b_condition:male`) * 60
  ) %>%
  gather(cell, yawns) %>%
  mutate(Condition   = rep(rep(c("Control", "Yawning"), each = 4000), times = 2),
         Sex         = rep(c("Female", "Male"), each = 8000)) %>%
  
  ggplot(aes(x = yawns, fill = Condition, colour = Condition)) +
  geom_density(alpha = 0.1) +
  xlab("Yawning rate (per min)") +
  xlim(c(0,0.6)) +
  facet_wrap(.~fct_rev(Sex)) +
  theme_classic() +
  theme(axis.line = element_blank(),
        axis.ticks = element_blank(),
        axis.text.y = element_blank(),
        axis.title.y = element_blank(),
        axis.title.x = element_text(margin = margin(t = 10)),
        legend.title = element_blank()) +
  annotation_custom2(ggplotGrob(insetMale), 
                     data=data.frame(Sex="Male", Condition = NA, yawns = 1),
                     xmin=0.25, xmax=0.6, ymin=8, ymax=14.2) +
  annotation_custom2(ggplotGrob(insetFemale), 
                     data=data.frame(Sex="Female", Condition = NA, yawns = 1),
                     xmin=0.25, xmax=0.6, ymin=8, ymax=14.2)
```

Let's compare all the condition/gender models.

```{r message=F, warning=F}
loo_compare(m1.1, m1.2, m1.11, m1.12, m1.13)
```

```{r echo=F, message=F, warning=F}
# visualise model comparison
looFig <-
  tibble(
    elpd_diff = c(loo_compare(m1.1, m1.2)[2]*-1,
                  loo_compare(m1.1, m1.11)[2]*-1,
                  loo_compare(m1.1, m1.12)[2]*-1,
                  loo_compare(m1.1, m1.13)[2]*-1,
                  loo_compare(m1.2, m1.11)[2],
                  loo_compare(m1.2, m1.12)[2],
                  loo_compare(m1.2, m1.13)[2]),
    se_diff = c(loo_compare(m1.1, m1.2)[4],
                  loo_compare(m1.1, m1.11)[4],
                  loo_compare(m1.1, m1.12)[4],
                  loo_compare(m1.1, m1.13)[4],
                  loo_compare(m1.2, m1.11)[4],
                  loo_compare(m1.2, m1.12)[4],
                  loo_compare(m1.2, m1.13)[4])
        ) %>%
  as.matrix() %>% as_tibble() %>% slice(1:7) %>%
  mutate(model = c("Treatment",
                   "Gender",
                   "Treatment+Gender",
                   "Treatment*Gender",
                   "Gender",
                   "Treatment+Gender",
                   "Treatment*Gender"))

looFig %>% slice(1:4) %>%
  ggplot(aes(x = fct_rev(factor(model, levels = model)), 
             y = elpd_diff, 
             ymin = elpd_diff - (se_diff*1.96), 
             ymax = elpd_diff + (se_diff*1.96))) +
  geom_pointrange(size = 0.35) +
  geom_hline(yintercept = 0, linetype = "dashed") +
  coord_flip() +
  xlab(NULL) +
  ylim(-50,50) +
  ylab("Difference in expected predictive accuracy\nfrom null model") +
  theme_classic()

looFig %>% slice(5:7) %>%
  ggplot(aes(x = fct_rev(factor(model, levels = model)), 
             y = elpd_diff, 
             ymin = elpd_diff - (se_diff*1.96), 
             ymax = elpd_diff + (se_diff*1.96))) +
  geom_pointrange(size = 0.35) +
  geom_hline(yintercept = 0, linetype = "dashed") +
  coord_flip() +
  xlab(NULL) +
  ylim(-50,50) +
  ylab("Difference in expected predictive accuracy\nfrom Treatment model") +
  theme_classic()
```

```{r echo=F}
# cleanup
rm(insetFemale, insetMale, looFig, post,
   cond1f, cond1m, cond2f, cond2m, diff1,
   diff2, diff3, diff4, diff5, diff6)
```

# 2. Fit Poisson models

## 2.1. Intercept-only model

We remove the assumption of zero-inflation and fit an intercept-only Poisson model.

```{r echo=F, eval=F}
m2.1 <- brm(data = d, family = poisson,
            numberYawns ~ 1 + offset(log(secs)) + (1 | study/ID),
            iter = 2000, warmup = 1000, chains = 4, cores = 4,
            control = list(adapt_delta = 0.99))

m2.1 <- add_criterion(m2.1, c("loo","waic"))

save(m2.1, file = 'models/m2.1.rda')
```

```{r echo=F}
load('models/m2.1.rda')
summary(m2.1)
```

Priors.

```{r echo=F}
prior_summary(m2.1)
```

```{r}
post <- posterior_samples(m2.1)

(exp(post$b_Intercept) * 60) %>% # Yawning rate (per min)
  median() %>%
  round(2)
```

The dogs yawn 0.09 times a minute, on average. Predictably, this is less than estimated by the zero-inflated model.

Model comparison?

```{r message=F, warning=F}
loo_compare(m1.1, m2.1)
```

The zero-inflated model is superior.

```{r echo=F}
# cleanup
rm(post)
```

## 2.2. Condition-only model

```{r echo=F, eval=F}
m2.2 <- brm(data = d, family = poisson,
            numberYawns ~ 0 + intercept + condition + offset(log(secs)) + 
              (0 + intercept + condition | study/ID),
            prior = c(prior(student_t(3, -2, 10), class = b, coef = "intercept"),
                      prior(normal(0, 1), class = b, coef = "condition")),
            iter = 2000, warmup = 1000, chains = 4, cores = 4,
            control = list(adapt_delta = 0.99, max_treedepth = 15))

m2.2 <- add_criterion(m2.2, c("loo","waic"))

save(m2.2, file = 'models/m2.2.rda')
```

```{r echo=F}
load('models/m2.2.rda')
summary(m2.2)
```

Priors.

```{r echo=F}
prior_summary(m2.2)
```

Get difference between conditions.

```{r}
post <- posterior_samples(m2.2)

# yawning rates (per minute)
cond1 <- exp(post$b_intercept) * 60
median(cond1) %>% round(2)

cond2 <- exp(post$b_intercept + post$b_condition) * 60
median(cond2) %>% round(2)

diff <- cond2 - cond1

# proportion of prob mass above zero
(sum(diff > 0) / length(diff)) %>% round(2)
```

Model comparison?

```{r message=F, warning=F}
loo_compare(m1.2, m2.2)
```

Again, this model is worse than its zero-inflated counterpart. For this reason, it's probably not worth re-running all the previous zero-inflated models as standard Poisson models.

```{r echo=F}
# cleanup
rm(post, cond1, cond2, diff)
```

# 3. Fit hurdle Poisson models

Unlike zero-inflated Poisson models, hurdle Poisson models assume that zeroes arise from an entirely different binomial process. Poisson rates are then truncated (do not contain zeroes).

## 3.1. Intercept-only model

```{r echo=F, eval=F}
m5.1 <- brm(data = d, family = hurdle_poisson,
            bf(numberYawns ~ 0 + intercept + offset(log(secs)) + 
              (0 + intercept | study/ID),
            hu ~ 0 + intercept + (0 + intercept | study/ID)),
            prior = c(prior(student_t(3, -2, 10), class = b, coef = "intercept"),
                      prior(logistic(0, 1), class = b, coef = "intercept", dpar = hu),
                      prior(student_t(3, 0, 0.5), class = sd, dpar = hu)),
            iter = 2000, warmup = 1000, chains = 4, cores = 4,
            control = list(adapt_delta = 0.99, max_treedepth = 15))

m5.1 <- add_criterion(m5.1, c("loo","waic"))

save(m5.1, file = 'models/m5.1.rda')
```

```{r echo=F}
load('models/m5.1.rda')
summary(m5.1)
```

Priors.

```{r echo=F}
prior_summary(m5.1)
```

Model comparison.

```{r echo=F, message=F, warning=F}
loo_compare(m1.1, m5.1)
```

Model comparison suggests that a hurdle Poisson model fits the data slightly better than a zero-inflated Poisson model.

## 3.2. Condition-only model

```{r echo=F, eval=F}
m5.2 <- brm(data = d, family = hurdle_poisson,
            bf(numberYawns ~ 0 + intercept + condition + offset(log(secs)) + 
              (0 + intercept + condition | study/ID),
            hu ~ 0 + intercept + condition + (0 + intercept + condition | study/ID)),
            prior = c(prior(student_t(3, -2, 10), class = b, coef = "intercept"),
                      prior(normal(0, 1), class = b, coef = "condition"),
                      prior(logistic(0, 1), class = b, coef = "intercept", dpar = hu),
                      prior(normal(0, 1), class = b, coef = "condition", dpar = hu),
                      prior(student_t(3, 0, 0.5), class = sd, dpar = hu)),
            iter = 3000, warmup = 1500, chains = 4, cores = 4,
            control = list(adapt_delta = 0.999, max_treedepth = 15))

m5.2 <- add_criterion(m5.2, c("loo","waic"))

save(m5.2, file = 'models/m5.2.rda')
```

```{r echo=F}
load("models/m5.2.rda")
summary(m5.2)
```

Priors.

```{r echo=F}
prior_summary(m5.2)
```

Get difference between conditions.

```{r}
post <- posterior_samples(m5.2)

# yawning rates (per minute)
cond1 <- exp(post$b_intercept) * 60
median(cond1) %>% round(2)

cond2 <- exp(post$b_intercept + post$b_condition) * 60
median(cond2) %>% round(2)

diff <- cond2 - cond1

# proportion of prob mass above zero
(sum(diff > 0) / length(diff))  %>% round(2)
```

Model comparison.

```{r echo=F, warning=F, message=F}
loo_compare(m1.2, m5.2)
```

Model comparison suggests that the hurdle Poisson model is better than the zero-inflated Poisson model.

```{r echo=F}
# cleanup
rm(post, cond1, cond2, diff)
```

# 4. Fit negative binomial models

Negative binomial models are much like Poisson models, but account for overdispersion in count data.

## 4.1. Intercept-only model

```{r echo=F, eval=F}
m6.1 <- brm(data = d, family = negbinomial,
            numberYawns ~ 0 + intercept + offset(log(secs)) + 
              (0 + intercept | study/ID),
            prior = prior(student_t(3, -2, 10), class = b, coef = "intercept"),
            iter = 2000, warmup = 1000, chains = 4, cores = 4,
            control = list(adapt_delta = 0.99, max_treedepth = 15))

m6.1 <- add_criterion(m6.1, c("loo","waic"))

save(m6.1, file = 'models/m6.1.rda')
```

```{r echo=F}
load('models/m6.1.rda')
summary(m6.1)
```

Priors.

```{r echo=F}
prior_summary(m6.1)
```

Model comparison.

```{r echo=F, message=F, warning=F}
loo_compare(m1.1, m2.1, m5.1, m6.1)
```

Hurdle Poisson model wins out again.

## 4.2. Condition-only model

```{r echo=F, eval=F}
m6.2 <- brm(data = d, family = negbinomial,
            numberYawns ~ 0 + intercept + condition + offset(log(secs)) + 
              (0 + intercept + condition | study/ID),
            prior = c(prior(student_t(3, -2, 10), class = b, coef = "intercept"),
                      prior(normal(0, 1), class = b, coef = "condition")),
            iter = 2000, warmup = 1000, chains = 4, cores = 4,
            control = list(adapt_delta = 0.99, max_treedepth = 15))

m6.2 <- add_criterion(m6.2, c("loo","waic"))

save(m6.2, file = 'models/m6.2.rda')
```

```{r echo=F}
load('models/m6.2.rda')
summary(m6.2)
```

Priors.

```{r echo=F}
prior_summary(m6.2)
```

Model comparison.

```{r echo=F, message=F, warning=F}
loo_compare(m1.2, m2.2, m5.2, m6.2)
```

Again, the hurdle Poisson model wins out.

# 5. Fit zero-inflated negative binomial models

Zero-inflated negative binomial models are as above, but assume a zero-inflation probability.

## 5.1. Intercept-only model

```{r echo=F, eval=F}
m7.1 <- brm(data = d, family = zero_inflated_negbinomial,
            bf(numberYawns ~ 0 + intercept + offset(log(secs)) + 
              (0 + intercept | study/ID),
              zi ~ 0 + intercept + (0 + intercept | study/ID)),
            prior = c(prior(student_t(3, -2, 10), class = b, coef = "intercept"),
                      prior(logistic(0, 1), class = b, coef = "intercept", dpar = zi),
                      prior(student_t(3, 0, 0.5), class = sd, dpar = zi)),
            iter = 4000, warmup = 2000, chains = 4, cores = 4,
            control = list(adapt_delta = 0.99, max_treedepth = 15))

m7.1 <- add_criterion(m7.1, c("loo","waic"))

save(m7.1, file = 'models/m7.1.rda')
```

```{r echo=F}
load('models/m7.1.rda')
summary(m7.1)
```

Model comparison.

```{r}
loo_compare(m1.1, m7.1)
```

Actually slightly worse than the zero-inflated Poisson model, suggesting that overdispersion is not too much of a problem after modelling zero-inflation.

## 5.2. Condition-only model

```{r echo=F, eval=F}
m7.2 <- brm(data = d, family = zero_inflated_negbinomial,
            bf(numberYawns ~ 0 + intercept + condition + offset(log(secs)) + 
              (0 + intercept + condition | study/ID),
              zi ~ 0 + intercept + condition + (0 + intercept + condition | study/ID)),
            prior = c(prior(student_t(3, -2, 10), class = b, coef = "intercept"),
                      prior(normal(0, 1), class = b, coef = "condition"),
                      prior(logistic(0, 1), class = b, coef = "intercept", dpar = zi),
                      prior(normal(0, 1), class = b, coef = "condition", dpar = zi),
                      prior(student_t(3, 0, 0.5), class = sd, dpar = zi)),
            iter = 4000, warmup = 2000, chains = 4, cores = 4,
            control = list(adapt_delta = 0.999, max_treedepth = 15))

m7.2 <- add_criterion(m7.2, c("loo","waic"))

save(m7.2, file = 'models/m7.2.rda')
```

```{r echo=F}
load('models/m7.2.rda')
summary(m7.2)
```

Model comparison.

```{r}
loo_compare(m1.2, m7.2)
```

Again, the negative binomial seems to be not necessary (ZI neg binomial performs worse than ZI Poisson).

# 6. Fit hurdle negative binomial models

Finally, hurdle negative binomial models treat zeroes as coming from an entirely separate binomial process, and model Poisson rates for >1 with an overdispersion parameter.

## 6.1. Intercept-only model

```{r echo=F, eval=F}
m8.1 <- brm(data = d, family = hurdle_negbinomial,
            bf(numberYawns ~ 0 + intercept + offset(log(secs)) + 
              (0 + intercept | study/ID),
              hu ~ 0 + intercept + (0 + intercept | study/ID)),
            prior = c(prior(student_t(3, -2, 10), class = b, coef = "intercept"),
                      prior(logistic(0, 1), class = b, coef = "intercept", dpar = hu),
                      prior(student_t(3, 0, 0.5), class = sd, dpar = hu)),
            iter = 4000, warmup = 2000, chains = 4, cores = 4,
            control = list(adapt_delta = 0.99, max_treedepth = 15))

m8.1 <- add_criterion(m8.1, c("loo","waic"))

save(m8.1, file = 'models/m8.1.rda')
```

```{r echo=F}
load('models/m8.1.rda')
summary(m8.1)
```

Model comparison.

```{r echo=F}
loo_compare(m1.1, m5.1, m8.1)
```

The hurdle negative binomial model is superior to the ZI Poisson model, but worse than the simpler hurdle Poisson model. This, again, suggests that overdispersion is not a problem in these data.

## 6.2. Condition-only model

```{r echo=F, eval=F}
m8.2 <- brm(data = d, family = hurdle_negbinomial,
            bf(numberYawns ~ 0 + intercept + condition + offset(log(secs)) + 
              (0 + intercept + condition | study/ID),
              hu ~ 0 + intercept + condition + (0 + intercept + condition | study/ID)),
            prior = c(prior(student_t(3, -2, 10), class = b, coef = "intercept"),
                      prior(normal(0, 1), class = b, coef = "condition"),
                      prior(logistic(0, 1), class = b, coef = "intercept", dpar = hu),
                      prior(normal(0, 1), class = b, coef = "condition", dpar = hu),
                      prior(student_t(3, 0, 0.5), class = sd, dpar = hu)),
            iter = 5000, warmup = 2500, chains = 4, cores = 4,
            control = list(adapt_delta = 0.999, max_treedepth = 15))

m8.2 <- add_criterion(m8.2, c("loo","waic"))

save(m8.2, file = 'models/m8.2.rda')
```

```{r echo=F}
load('models/m8.2.rda')
summary(m8.2)
```

Model comparison.

```{r}
loo_compare(m1.2, m8.2)
```

What if we compare all the different kinds of models?

```{r}
loo_compare(m1.1, m2.1, m5.1, m6.1, m7.1, m8.1)
loo_compare(m1.2, m2.2, m5.2, m6.2, m7.2, m8.2)
```

For both intercept-only and condition models, the winner is the hurdle Poisson model class.

# Session Info

```{r}
sessionInfo()
```