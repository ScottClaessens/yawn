---
title: "Contagious Yawning in Dogs: Prosocial Experiment Analysis (Part 1)"
author: Scott Claessens and Patrick Neilands
date: "`r format(Sys.Date())`"
output:
  html_document:
    df_print: paged
    toc: true
    number_sections: false
    toc_float: true
---

The purpose of this document is to analyse data from a new experiment on contagious yawning in dogs in the presence of either a prosocial or antisocial demonstrator.

# 0. Setup

```{r echo=FALSE, cache=FALSE, include=FALSE}
options(width = 120)

library(tidyverse)
library(brms)
library(tidybayes)
library(bayesplot)
library(brmstools)
library(cowplot)
```

Load the data.

```{r}
d <-
  read.csv("data/yawnProsocial.csv") %>%
  as_tibble() %>%
  # create dummy variables for analysis
  mutate(condition = ifelse(condition == "Anti-Social", 0, 1),
         trial     = ifelse(trial == 1, 0, 1))

d
```

We can visualize the number of yawns across the sample as a whole. 

```{r warning=F, message=F, echo=F}
d %>%
  ggplot(aes(x = numberYawns)) +
  geom_histogram(binwidth = 0.5) +
  labs(x = 'Number of yawns')
```

We can also see how this varies by condition.

```{r warning=F, message=F, echo=F}
d %>%
  ggplot(aes(x = numberYawns)) +
  geom_histogram(binwidth = 0.5) +
  labs(x = 'Number of yawns') +
  facet_wrap(.~condition)
```

We will initially treat this as zero-inflated Poisson data; however, this specific dataset does not look too zero-inflated. Later, we will re-run models with other distributions and see if our results are robust to this assumption.

# 1. Fit zero-inflated Poisson models

## 1.1. Intercept-only model

We utlise a Bayesian multilevel modelling approach, including random effects for individual dogs. Throughout, we use the same linear model to predict $\lambda_i$ (the rate of yawning) and $p_i$ (the probability of the yawning process never even getting started). The latter is called `zi` inside the model formula.

Fit an intercept-only model.

```{r eval=F, echo=F}
m3.1 <- brm(data = d, family = zero_inflated_poisson,
            bf(numberYawns ~ 0 + intercept + offset(log(secs)) + (0 + intercept | ID),
               zi ~ 0 + intercept + (0 + intercept | ID)),
            prior = c(prior(student_t(3, -2, 10), class = b, coef = "intercept"),
                      prior(logistic(0, 1), class = b, coef = "intercept", dpar = zi),
                      prior(student_t(3, 0, 0.5), class = sd, dpar = zi)),
            iter = 2000, warmup = 1000, chains = 4, cores = 4,
            control = list(adapt_delta = 0.999))

m3.1 <- add_criterion(m3.1, c("loo","waic"))

save(m3.1, file = 'models/m3.1.rda')
```

```{r echo=F}
load('models/m3.1.rda')
summary(m3.1)
```

What priors did we use?

```{r echo=F}
prior_summary(m3.1)
```

Let's interpret each parameter in turn. The zero-inflation parameter `zi` is -2.33. This is on the logit scale, so we need to calculate the inverse logit.

```{r}
post <- posterior_samples(m3.1)

1 - inv_logit_scaled(post$b_zi_intercept) %>% # prob of yawning process getting started
  median() %>%
  round(2)
```

The median probability of the yawning process getting started is 0.89. This is quite probable, meaning we may be justified in switching to a non-zero-inflated Poisson process. We'll do this later.

Let's calculate the average yawning rate once the yawning process gets started.

```{r}
(exp(post$b_intercept) * 60) %>% # Yawning rate (per min)
  median() %>%
  round(2)
```

The dogs yawn 0.19 times a minute, on average. Let's split this by ID.

```{r warning=F, message=F, echo=F}
brmstools::forest(m3.1, pars = 'intercept', grouping = 'ID')
```

Remember, this is on the log scale. But it seems like there isn't much variation in yawning rates across dogs.

```{r echo=F}
# cleanup
rm(post)
```

## 1.2. Condition-only model

Next, we add condition to the model, also as a random effect grouped by individual dogs.

```{r eval=F, echo=F}
m3.2 <- brm(data = d, family = zero_inflated_poisson,
            bf(numberYawns ~ 0 + intercept + condition + offset(log(secs)) + 
                 (0 + intercept + condition | ID),
               zi ~ 0 + intercept + condition + 
                 (0 + intercept + condition | ID)),
            prior = c(prior(student_t(3, -2, 10), class = b, coef = "intercept"),
                      prior(normal(0, 1), class = b, coef = "condition"),
                      prior(logistic(0, 1), class = b, coef = "intercept", dpar = zi),
                      prior(normal(0, 1), class = b, coef = "condition", dpar = zi),
                      prior(student_t(3, 0, 0.5), class = sd, dpar = zi)),
            iter = 2000, warmup = 1000, chains = 4, cores = 4,
            control = list(adapt_delta = 0.999))

m3.2 <- add_criterion(m3.2, c("loo","waic"))

save(m3.2, file = 'models/m3.2.rda')
```

```{r echo=F}
load('models/m3.2.rda')
summary(m3.2)
```

What priors did we use?

```{r echo=F}
prior_summary(m3.2)
```

The condition parameter has 95% CIs crossing zero, suggesting that there is no difference in yawning rates between conditions. Let's calculate this directly.

```{r}
post <- posterior_samples(m3.2)

# Yawning rate (per min) in Anti-Social condition
(exp(post$b_intercept) * 60) %>%
  median() %>%
  round(2)

# Yawning rate (per min) in Pro-Social condition
(exp(post$b_intercept + post$b_condition) * 60) %>%
  median() %>%
  round(2)
```

Psoterior probability mass shows that the difference between these is not substantial.

```{r}
(sum(post$b_condition < 0) / length(post$b_condition)) %>% round(2)
```

Let's visualise this lack of a difference on the "Yawning rate (per min)" scale.

```{r echo=F, warning=F, message=F}
inset <-
  tibble(
    diff  = (exp(post$b_intercept) - exp(post$b_intercept + post$b_condition)) * 60
    ) %>%
  ggplot(aes(x = diff)) +
  geom_density(fill = "grey90") +
  geom_vline(xintercept = 0, linetype = "dashed") +
  xlab("difference") +
  xlim(c(-0.25,0.5)) +
  theme_classic() +
  theme(axis.line = element_blank(),
        axis.ticks = element_blank(),
        axis.text.y = element_blank(),
        axis.title.y = element_blank(),
        text = element_text(size = 9))

tibble(
  Antisocial = exp(post$b_intercept) * 60,
  Prosocial  = exp(post$b_intercept + post$b_condition) * 60
  ) %>%
  gather(Condition, yawns) %>%
  
  ggplot(aes(x = yawns, fill = Condition, colour = Condition)) +
  geom_density(alpha = 0.1) +
  xlab("Yawning rate (per min)") +
  xlim(c(0, 0.6)) +
  theme_classic() +
  theme(axis.line = element_blank(),
        axis.ticks = element_blank(),
        axis.text.y = element_blank(),
        axis.title.y = element_blank(),
        axis.title.x = element_text(margin = margin(t = 10)),
        legend.title = element_blank()) +
  annotation_custom(ggplotGrob(inset), xmin = 0.35, xmax = 0.6,
                    ymin = 5, ymax = 10)
```

How does the effect of condition vary across individual dogs?

```{r echo=F, warning=F, message=F}
brmstools::forest(m3.2, pars = 'condition', grouping = 'ID') +
  geom_vline(xintercept = 0, linetype = "dashed")
```

Condition doesn't seem to have an effect for any individual dog either.

```{r echo=F}
# cleanup
rm(inset, post)
```

## 1.3. Trial-only model

```{r eval=F, echo=F}
m3.3 <- brm(data = d, family = zero_inflated_poisson,
            bf(numberYawns ~ 0 + intercept + trial + offset(log(secs)) + 
                 (0 + intercept + trial | ID),
               zi ~ 0 + intercept + trial + 
                 (0 + intercept + trial | ID)),
            prior = c(prior(student_t(3, -2, 10), class = b, coef = "intercept"),
                      prior(normal(0, 1), class = b, coef = "trial"),
                      prior(logistic(0, 1), class = b, coef = "intercept", dpar = zi),
                      prior(normal(0, 1), class = b, coef = "trial", dpar = zi),
                      prior(student_t(3, 0, 0.5), class = sd, dpar = zi)),
            iter = 2000, warmup = 1000, chains = 4, cores = 4,
            control = list(adapt_delta = 0.999, max_treedepth = 15))

m3.3 <- add_criterion(m3.3, c("loo","waic"))

save(m3.3, file = 'models/m3.3.rda')
```

```{r echo=F}
load('models/m3.3.rda')
summary(m3.3)
```

Priors.

```{r echo=F}
prior_summary(m3.3)
```

## 1.4. Condition + Trial model

```{r eval=F, echo=F}
m3.4 <- brm(data = d, family = zero_inflated_poisson,
            bf(numberYawns ~ 0 + intercept + condition + trial + offset(log(secs)) + 
                 (0 + intercept + condition + trial | ID),
               zi ~ 0 + intercept + condition + trial + 
                 (0 + intercept + condition + trial | ID)),
            prior = c(prior(student_t(3, -2, 10), class = b, coef = "intercept"),
                      prior(normal(0, 1), class = b, coef = "condition"),
                      prior(normal(0, 1), class = b, coef = "trial"),
                      prior(logistic(0, 1), class = b, coef = "intercept", dpar = zi),
                      prior(normal(0, 1), class = b, coef = "condition", dpar = zi),
                      prior(normal(0, 1), class = b, coef = "trial", dpar = zi),
                      prior(student_t(3, 0, 0.5), class = sd, dpar = zi)),
            iter = 2000, warmup = 1000, chains = 4, cores = 4,
            control = list(adapt_delta = 0.999))

m3.4 <- add_criterion(m3.4, c("loo","waic"))

save(m3.4, file = 'models/m3.4.rda')
```

```{r echo=F}
load('models/m3.4.rda')
summary(m3.4)
```

Priors.

```{r echo=F}
prior_summary(m3.4)
```

## 1.5. Interaction model

```{r eval=F, echo=F}
m3.5 <- brm(data = d, family = zero_inflated_poisson,
            bf(numberYawns ~ 0 + intercept + condition*trial + offset(log(secs)) + 
                 (0 + intercept + condition*trial | ID),
               zi ~ 0 + intercept + condition*trial + 
                 (0 + intercept + condition*trial | ID)),
            prior = c(prior(student_t(3, -2, 10), class = b, coef = "intercept"),
                      prior(normal(0, 1), class = b, coef = "condition"),
                      prior(normal(0, 1), class = b, coef = "trial"),
                      prior(normal(0, 1), class = b, coef = "condition:trial"),
                      prior(logistic(0, 1), class = b, coef = "intercept", dpar = zi),
                      prior(normal(0, 1), class = b, coef = "condition", dpar = zi),
                      prior(normal(0, 1), class = b, coef = "trial", dpar = zi),
                      prior(normal(0, 1), class = b, coef = "condition:trial", dpar = zi),
                      prior(student_t(3, 0, 0.5), class = sd, dpar = zi)),
            iter = 2000, warmup = 1000, chains = 4, cores = 4,
            control = list(adapt_delta = 0.999))

m3.5 <- add_criterion(m3.5, c("loo","waic"))

save(m3.5, file = 'models/m3.5.rda')
```

```{r echo=F}
load('models/m3.5.rda')
summary(m3.5)
```

What priors did we use?

```{r echo=F}
prior_summary(m3.5)
```

Are there any differences between cells in the 2x2 design?

```{r}
post <- posterior_samples(m3.5)

# Yawning rate (per min)
anti1rate <- exp(post$b_intercept) * 60
anti2rate <- exp(post$b_intercept + post$b_trial) * 60
pro1rate  <- exp(post$b_intercept + post$b_condition) * 60
pro2rate  <- exp(post$b_intercept + post$b_condition + post$b_trial + post$`b_condition:trial`) * 60

diff1 <- anti1rate - anti2rate 
diff2 <- anti1rate - pro1rate  
diff3 <- anti1rate - pro2rate  
diff4 <- anti2rate - pro1rate  
diff5 <- anti2rate - pro2rate  
diff6 <- pro1rate  - pro2rate

(sum(diff1 > 0) / length(diff1)) %>% round(2)
(sum(diff2 > 0) / length(diff2)) %>% round(2)
(sum(diff3 > 0) / length(diff3)) %>% round(2)
(sum(diff4 > 0) / length(diff4)) %>% round(2)
(sum(diff5 > 0) / length(diff5)) %>% round(2)
(sum(diff6 > 0) / length(diff6)) %>% round(2)
```

Is there an interaction effect?

```{r}
(sum(diff2 - diff5 < 0) / length(diff2)) %>% round(2)
```

No.

```{r echo=F}
# cleanup
rm(post, anti1rate, anti2rate, pro1rate, pro2rate,
   diff1, diff2, diff3, diff4, diff5, diff6)
```

## 1.6. Compare models

```{r}
loo_compare(m3.1, m3.2, m3.3, m3.4, m3.5)
```

```{r echo=F}
# visualise model comparison
tibble(
    elpd_diff = c(loo_compare(m3.1, m3.2)[2],
                  loo_compare(m3.1, m3.3)[2],
                  loo_compare(m3.1, m3.4)[2],
                  loo_compare(m3.1, m3.5)[2]),
    se_diff = c(loo_compare(m3.1, m3.2)[4],
                  loo_compare(m3.1, m3.3)[4],
                  loo_compare(m3.1, m3.4)[4],
                  loo_compare(m3.1, m3.5)[4])
        ) %>%
  as.matrix() %>% as_tibble() %>%
  mutate(model = c("Prosocial",
                   "Trial",
                   "Prosocial+Trial",
                   "Prosocial*Trial")) %>%
  
  ggplot(aes(x = fct_rev(factor(model, levels = model)), 
             y = elpd_diff, 
             ymin = elpd_diff - (se_diff*1.96), 
             ymax = elpd_diff + (se_diff*1.96))) +
  geom_pointrange(size = 0.35) +
  geom_hline(yintercept = 0, linetype = "dashed") +
  coord_flip() +
  xlab(NULL) +
  ylim(-8,8) +
  ylab("Difference in expected predictive accuracy\nfrom null model") +
  theme_classic()
```

# 2. Fit Poisson models

## 2.1. Intercept-only model

Fit an intercept-only model with no zero-inflation assumption.

```{r eval=F, echo=F}
m4.1 <- brm(data = d, family = poisson,
            numberYawns ~ 1 + offset(log(secs)) + (1 | ID),
            iter = 2000, warmup = 1000, chains = 4, cores = 4,
            control = list(adapt_delta = 0.999))

m4.1 <- add_criterion(m4.1, c("loo","waic"))

save(m4.1, file = 'models/m4.1.rda')
```

```{r echo=F}
load('models/m4.1.rda')
summary(m4.1)
```

What priors did we use?

```{r echo=F}
prior_summary(m4.1)
```

Calculate the average yawning rate.

```{r}
post <- posterior_samples(m4.1)

(exp(post$b_Intercept) * 60) %>% # Yawning rate (per min)
  median() %>%
  round(2)
```

The dogs yawn 0.16 times a minute, on average. Not much different from the zero-inflated model. Quick model comparison?

```{r}
loo_compare(m3.1, m4.1)
```

The two models perform no differently.

## 2.2. Condition-only model

Add condition to the model.

```{r eval=F, echo=F}
m4.2 <- brm(data = d, family = poisson,
            numberYawns ~ 0 + intercept + condition + offset(log(secs)) + 
               (0 + intercept + condition | ID),
            prior = c(prior(student_t(3, -2, 10), class = b, coef = "intercept"),
                      prior(normal(0, 1), class = b, coef = "condition")),
            iter = 2000, warmup = 1000, chains = 4, cores = 4,
            control = list(adapt_delta = 0.999))

m4.2 <- add_criterion(m4.2, c("loo","waic"))

save(m4.2, file = 'models/m4.2.rda')
```

```{r echo=F}
load('models/m4.2.rda')
summary(m4.2)
```

What priors did we use?

```{r echo=F}
prior_summary(m4.2)
```

Difference between conditions?

```{r}
post <- posterior_samples(m4.2)

# Yawning rate (per min) in Anti-Social condition
(exp(post$b_intercept) * 60) %>%
  median() %>%
  round(2)

# Yawning rate (per min) in Pro-Social condition
(exp(post$b_intercept + post$b_condition) * 60) %>%
  median() %>%
  round(2)
```

Estimates are not much different from the zero-inflated model. Again, posterior probability mass shows that the difference between these is not substantial.

```{r}
(sum(post$b_condition < 0) / length(post$b_condition)) %>% round(2)
```

Let's visualise the difference with our Poisson model.

```{r echo=F, warning=F, message=F}
tibble(
    Antisocial = exp(post$b_intercept) * 60,
    Prosocial  = exp(post$b_intercept + post$b_condition) * 60
    ) %>%
  gather(Condition, yawns) %>%
  
  ggplot(aes(x = yawns, fill = Condition, colour = Condition)) +
  geom_density(alpha = 0.1) +
  xlim(c(0,0.6)) +
  xlab("Yawning rate (per min)") +
  theme_classic() +
  theme(axis.line = element_blank(),
        axis.ticks = element_blank(),
        axis.text.y = element_blank(),
        axis.title.y = element_blank(),
        axis.title.x = element_text(margin = margin(t = 10)),
        legend.title = element_blank())
```

Quick model comparison?

```{r}
loo_compare(m3.2, m4.2)
```

The model types are no different.

```{r echo=F}
# cleanup
rm(post)
```

## 2.3. Trial-only model

```{r eval=F, echo=F}
m4.3 <- brm(data = d, family = poisson,
            numberYawns ~ 0 + intercept + trial + offset(log(secs)) + 
                 (0 + intercept + trial | ID),
            prior = c(prior(student_t(3, -2, 10), class = b, coef = "intercept"),
                      prior(normal(0, 1), class = b, coef = "trial")),
            iter = 2000, warmup = 1000, chains = 4, cores = 4,
            control = list(adapt_delta = 0.999))

m4.3 <- add_criterion(m4.3, c("loo","waic"))

save(m4.3, file = 'models/m4.3.rda')
```

```{r echo=F}
load('models/m4.3.rda')
summary(m4.3)
```

Priors.

```{r echo=F}
prior_summary(m4.3)
```

## 2.4. Condition + Trial model

```{r eval=F, echo=F}
m4.4 <- brm(data = d, family = poisson,
          numberYawns ~ 0 + intercept + condition + trial + offset(log(secs)) + 
               (0 + intercept + condition + trial | ID),
          prior = c(prior(student_t(3, -2, 10), class = b, coef = "intercept"),
                    prior(normal(0, 1), class = b, coef = "condition"),
                    prior(normal(0, 1), class = b, coef = "trial")),
          iter = 2000, warmup = 1000, chains = 4, cores = 4,
          control = list(adapt_delta = 0.999))

m4.4 <- add_criterion(m4.4, c("loo","waic"))

save(m4.4, file = 'models/m4.4.rda')
```

```{r echo=F}
load('models/m4.4.rda')
summary(m4.4)
```

Priors.

```{r echo=F}
prior_summary(m4.4)
```

## 2.5. Interaction model

```{r eval=F, echo=F}
m4.5 <- brm(data = d, family = poisson,
          numberYawns ~ 0 + intercept + condition*trial + offset(log(secs)) + 
               (0 + intercept + condition*trial | ID),
          prior = c(prior(student_t(3, -2, 10), class = b, coef = "intercept"),
                    prior(normal(0, 1), class = b, coef = "condition"),
                    prior(normal(0, 1), class = b, coef = "trial"),
                    prior(normal(0, 1), class = b, coef = "condition:trial")),
          iter = 2000, warmup = 1000, chains = 4, cores = 4,
          control = list(adapt_delta = 0.999))

m4.5 <- add_criterion(m4.5, c("loo","waic"))

save(m4.5, file = 'models/m4.5.rda')
```

```{r echo=F}
load('models/m4.5.rda')
summary(m4.5)
```

What priors did we use?

```{r echo=F}
prior_summary(m4.5)
```

## 2.6. Compare models

Let's compare every model fitted so far.

```{r}
loo_compare(m3.1, m3.2, m3.3, m3.4, m3.5,
            m4.1, m4.2, m4.3, m4.4, m4.5)
```

These models are indistinguishable.

# 3. Fit hurdle Poisson models

After running further model types for our main reanalysis, it transpired that a hurdle Poisson model fitted the data better than a zero-inflated Poisson model. We test this with our experimental data too.

## 3.1. Intercept-only model

```{r eval=F, echo=F}
m9.1 <- brm(data = d, family = hurdle_poisson,
            bf(numberYawns ~ 0 + intercept + offset(log(secs)) + (0 + intercept | ID),
               hu ~ 0 + intercept + (0 + intercept | ID)),
            prior = c(prior(student_t(3, -2, 10), class = b, coef = "intercept"),
                      prior(logistic(0, 1), class = b, coef = "intercept", dpar = hu),
                      prior(student_t(3, 0, 0.5), class = sd, dpar = hu)),
            iter = 2000, warmup = 1000, chains = 4, cores = 4,
            control = list(adapt_delta = 0.999))

m9.1 <- add_criterion(m9.1, c("loo","waic"))

save(m9.1, file = 'models/m9.1.rda')
```

```{r echo=F}
load('models/m9.1.rda')
summary(m9.1)
```

Model comparison.

```{r}
loo_compare(m3.1, m9.1)
```

A hurdle model is no better than a zero-inflated model.

## 3.2. Condition-only model

```{r eval=F, echo=F}
m9.2 <- brm(data = d, family = hurdle_poisson,
            bf(numberYawns ~ 0 + intercept + condition + offset(log(secs)) + 
                 (0 + intercept  + condition | ID),
               hu ~ 0 + intercept + condition + (0 + intercept + condition | ID)),
            prior = c(prior(student_t(3, -2, 10), class = b, coef = "intercept"),
                      prior(normal(0, 1), class = b, coef = "condition"),
                      prior(logistic(0, 1), class = b, coef = "intercept", dpar = hu),
                      prior(normal(0, 1), class = b, coef = "condition", dpar = hu),
                      prior(student_t(3, 0, 0.5), class = sd, dpar = hu)),
            iter = 2000, warmup = 1000, chains = 4, cores = 4,
            control = list(adapt_delta = 0.999))

m9.2 <- add_criterion(m9.2, c("loo","waic"))

save(m9.2, file = 'models/m9.2.rda')
```

```{r echo=F}
load('models/m9.2.rda')
summary(m9.2)
```

Model comparison.

```{r}
loo_compare(m3.2, m9.2)
```

Both model classes perform similarly.

# 4. Fit various negative binomial models

For completion's sake, we also fit NB models that deal with overdispersion in the data.

## 4.1. Negative binomial models

### 4.1.1. Intercept-only model

```{r eval=F, echo=F}
m10.1 <- brm(data = d, family = negbinomial,
            numberYawns ~ 0 + intercept + offset(log(secs)) + (0 + intercept | ID),
            prior = prior(student_t(3, -2, 10), class = b, coef = "intercept"),
            iter = 2000, warmup = 1000, chains = 4, cores = 4,
            control = list(adapt_delta = 0.99))

m10.1 <- add_criterion(m10.1, c("loo","waic"))

save(m10.1, file = 'models/m10.1.rda')
```

```{r echo=F}
load('models/m10.1.rda')
summary(m10.1)
```

Model comparison.

```{r echo=F}
loo_compare(m3.1, m4.1, m9.1, m10.1)
```

All are comparable.

### 4.1.2. Condition-only model

```{r eval=F, echo=F}
m10.2 <- brm(data = d, family = negbinomial,
            numberYawns ~ 0 + intercept + condition + offset(log(secs)) + (0 + intercept + condition | ID),
            prior = c(prior(student_t(3, -2, 10), class = b, coef = "intercept"),
                      prior(normal(0, 1), class = b, coef = "condition")),
            iter = 2000, warmup = 1000, chains = 4, cores = 4,
            control = list(adapt_delta = 0.99))

m10.2 <- add_criterion(m10.2, c("loo","waic"))

save(m10.2, file = 'models/m10.2.rda')
```

```{r echo=F}
load('models/m10.2.rda')
summary(m10.2)
```

Model comparison.

```{r}
loo_compare(m3.2, m4.2, m9.2, m10.2)
```

Again, the models are comparable.

## 4.2. Zero-inflated negative binomial models

### 4.2.1. Intercept-only model

```{r eval=F, echo=F}
m11.1 <- brm(data = d, family = zero_inflated_negbinomial,
            bf(numberYawns ~ 0 + intercept + offset(log(secs)) + (0 + intercept | ID),
               zi ~ 0 + intercept + (0 + intercept | ID)),
            prior = c(prior(student_t(3, -2, 10), class = b, coef = "intercept"),
                      prior(logistic(0, 1), class = b, coef = "intercept", dpar = zi),
                      prior(student_t(3, 0, 0.5), class = sd, dpar = zi)),
            iter = 2000, warmup = 1000, chains = 4, cores = 4,
            control = list(adapt_delta = 0.999))

m11.1 <- add_criterion(m11.1, c("loo","waic"))

save(m11.1, file = 'models/m11.1.rda')
```

```{r echo=F}
load('models/m11.1.rda')
summary(m11.1)
```

Model comparison.

```{r}
loo_compare(m3.1, m4.1, m9.1, m10.1, m11.1)
```

### 4.2.2. Condition-only model

```{r eval=F, echo=F}
m11.2 <- brm(data = d, family = zero_inflated_negbinomial,
            bf(numberYawns ~ 0 + intercept + condition + offset(log(secs)) + (0 + intercept + condition | ID),
               zi ~ 0 + intercept + condition + (0 + intercept + condition | ID)),
            prior = c(prior(student_t(3, -2, 10), class = b, coef = "intercept"),
                      prior(normal(0, 1), class = b, coef = "condition"),
                      prior(logistic(0, 1), class = b, coef = "intercept", dpar = zi),
                      prior(normal(0, 1), class = b, coef = "condition", dpar = zi),
                      prior(student_t(3, 0, 0.5), class = sd, dpar = zi)),
            iter = 2000, warmup = 1000, chains = 4, cores = 4,
            control = list(adapt_delta = 0.999))

m11.2 <- add_criterion(m11.2, c("loo","waic"))

save(m11.2, file = 'models/m11.2.rda')
```

```{r echo=F}
load('models/m11.2.rda')
summary(m11.2)
```

Model comparison.

```{r}
loo_compare(m3.2, m4.2, m9.2, m10.2, m11.2)
```

All models are comparable.

## 4.3. Hurdle negative binomial models

Unfortunately, this model class does not converge in brms with these data.

# Session Info

```{r}
sessionInfo()
```