---
title: "Contagious Yawning in Dogs: A Re-analysis"
author: Scott Claessens and Patrick Neilands
date: "`r format(Sys.Date())`"
output:
  html_document:
    df_print: paged
    toc: true
    number_sections: false
    toc_float: true
---

The purpose of this document is to re-analyse the data from seven studies of contagious yawning in dogs. These studies are:

- [Joly-Mascheroni et al. (2008)](https://royalsocietypublishing.org/doi/abs/10.1098/rsbl.2008.0333)
- [Harr et al. (2009)](https://link.springer.com/article/10.1007/s10071-009-0233-0)
- [Oâ€™Hara & Reeve (2011)](https://www.sciencedirect.com/science/article/pii/S0003347210004483)
- [Silva et al. (2012)](https://link.springer.com/article/10.1007/s10071-012-0473-2)
- [Madsen & Persson (2013)](https://link.springer.com/article/10.1007/s10071-012-0568-9)
- [Romero et al. (2013)](https://journals.plos.org/plosone/article?id=10.1371/journal.pone.0071365)
- [Buttner & Strasser (2014)](https://link.springer.com/article/10.1007/s10071-013-0641-z)

We would like to thank the authors of these studies for kindly sharing their original data with us.

# 0. Setup

Load packages.

```{r warning=F, message=F}
library(tidyverse)
library(brms)
library(tidybayes)
library(bayesplot)
library(brmstools)
```

Load the data.

```{r}
d <- 
  read.csv('data/yawn.csv') %>%
  as_tibble() %>%
  # create new column for modelling interaction effect
  mutate(int = paste(condition, familiar, sep=""))

d
```

Visualise the outcome.

```{r message=F, warning=F}
d %>%
  ggplot(aes(x = numberYawns)) +
  geom_histogram(binwidth = 0.5) +
  labs(x = 'Number of yawns')
```

And split by study.

```{r message=F, warning=F}
d %>%
  ggplot(aes(x = numberYawns)) +
  geom_histogram(binwidth = 0.5) +
  labs(x = 'Number of yawns') +
  facet_wrap(.~study)
```

These look pretty zero-inflated to me! A zero-inflated Poisson model follows the general form

$$
\begin{eqnarray}
y_i & \sim & \text{ZIPoisson} (p_i, \lambda_i)\\
\text{logit} (p_i) & = & \alpha_p  + \beta_p x_i \\
\text{log} (\lambda_i) & = & \alpha_\lambda + \text{log(offset)} + \beta_\lambda x_i
\end{eqnarray}
$$

where $p_i$ is the zero-inflation probability (so $1 - p_i$ is the probability of the process getting started). $\text{log(offset)}$ is the log of the exposure length, and simple algebra means that $\lambda_i$ is now the expected *rate* per exposure length, rather than the count.

# 1. Fit models

## 1.1. Intercept-only model

We utlise a Bayesian multilevel modelling approach here, including random effects for individual dogs nested within studies. Throughout, we use the same linear model to predict $\lambda_i$ (the rate of yawning) and $p_i$ (the probability of the yawning process never even getting started). The latter is called `zi` inside the model formula. 

To begin, we fit an intercept-only model.

```{r eval=F}
m1 <- brm(data = d, family = zero_inflated_poisson,
          bf(numberYawns ~ 1 + offset(log(secs)) + (1 | study/ID),
             zi ~ 1 + (1 | study/ID)),
          iter = 2000, warmup = 1000, chains = 4, cores = 4,
          control = list(adapt_delta = 0.99))

m1 <- add_waic(m1)
m1 <- add_loo(m1)

save(m1, file = 'models/m1.rda')
```

```{r echo=F}
load('models/m1.rda')
```

We used default priors.

```{r}
prior_summary(m1)
```

Did the model run well? We should look at diagnostics like Rhat and Neff.

```{r}
print(m1)
```

Diagnostics look good.

Let's interpret each parameter in turn. The zero-inflation parameter `zi` is xxxxx. This is on the logit scale, so we need to calculate the inverse logit.

```{r}
post <- posterior_samples(m1)

1 - inv_logit_scaled(post$b_zi_Intercept) %>% # prob of yawning process getting started
  median() %>%
  round(2)
```

The median probability of the yawning process getting started is xxxxxx.

Let's calculate the average yawning rate once the yawning process gets started.

```{r}
(exp(post$b_Intercept) * 60) %>% # yawns per minute
  median() %>%
  round(2)
```

The dogs yawn xxxxx times a minute, on average. Let's split this by study.

```{r}
brmstools::forest(m1, pars = 'Intercept', grouping = 'study') %>%
  scale_x_continuous(trans='log')
```

Average yawning rate is lowest in BT et al, but highest in SIL et al.

## 1.2. Condition-only model

Next, we add condition to the model, also as a random effect grouped by individual dogs nested within studies.

```{r eval=F}
m2 <- brm(data = d, family = zero_inflated_poisson,
          bf(numberYawns ~ 0 + condition + offset(log(secs)) + (0 + condition | study/ID),
             zi ~ 0 + condition + (0 + condition | study/ID)),
          # set priors for both conditions and both linear models
          prior = c(prior(student_t(3, -2, 10), class = b, coef = conditionControl),
                    prior(student_t(3, -2, 10), class = b, coef = conditionYawning),
                    prior(logistic(0, 1), class = b, coef = conditionControl, dpar = zi),
                    prior(logistic(0, 1), class = b, coef = conditionYawning, dpar = zi)),
          iter = 2000, warmup = 1000, chains = 4, cores = 4,
          control = list(adapt_delta = 0.99))

m2 <- add_waic(m2)
m2 <- add_loo(m2)

save(m2, file = 'models/m2.rda')
```

```{r echo=F}
load('models/m2.rda')
```

What priors did we use?

```{r}
prior_summary(m2)
```

Did the model run well? We should look at diagnostics like Rhat and Neff.

```{r}
print(m2)
```

Diagnostics look good.

## 1.3. Familiarity-only model

We replace condition with familiarity in the model, again as a random effect grouped by individual dogs nested within studies.

```{r eval=F}
m3 <- brm(data = d, family = zero_inflated_poisson,
          bf(numberYawns ~ 0 + familiar + offset(log(secs)) + (0 + familiar | study/ID),
             zi ~ 0 + familiar + (0 + familiar | study/ID)),
          # set priors for both conditions and both linear models
          prior = c(prior(student_t(3, -2, 10), class = b, coef = familiarFamiliar),
                    prior(student_t(3, -2, 10), class = b, coef = familiarUnfamiliar),
                    prior(logistic(0, 1), class = b, coef = familiarFamiliar, dpar = zi),
                    prior(logistic(0, 1), class = b, coef = familiarUnfamiliar, dpar = zi)),
          iter = 2000, warmup = 1000, chains = 4, cores = 4,
          control = list(adapt_delta = 0.99))

m3 <- add_waic(m3)
m3 <- add_loo(m3)

save(m3, file = 'models/m3.rda')
```

```{r echo=F}
load('models/m3.rda')
```

What priors did we use?

```{r}
prior_summary(m3)
```

Did the model run well? We should look at diagnostics like Rhat and Neff.

```{r}
print(m3)
```

Diagnostics look good.

## 1.4. Interaction model

Finally, we model the interaction between condition and familiarity. We use an indexing approach to interactions, whereby we simply give each "cell" in the 2x2 design its own intercept, and allow these intercepts to vary by study and ID.

```{r eval=F}
m4 <- brm(data = d, family = zero_inflated_poisson,
          bf(numberYawns ~ 0 + int + offset(log(secs)) + (0 + int | study/ID),
             zi ~ 0 + int + (0 + int | study/ID)),
          # set priors for both conditions and both linear models
          prior = c(prior(student_t(3, -2, 10), class = b, coef = intControlFamiliar),
                    prior(student_t(3, -2, 10), class = b, coef = intControlUnfamiliar),
                    prior(student_t(3, -2, 10), class = b, coef = intYawningFamiliar),
                    prior(student_t(3, -2, 10), class = b, coef = intYawningUnfamiliar),
                    prior(logistic(0, 1), class = b, coef = intControlFamiliar, dpar = zi),
                    prior(logistic(0, 1), class = b, coef = intControlUnfamiliar, dpar = zi),
                    prior(logistic(0, 1), class = b, coef = intYawningFamiliar, dpar = zi),
                    prior(logistic(0, 1), class = b, coef = intYawningUnfamiliar, dpar = zi)),
          iter = 2000, warmup = 1000, chains = 4, cores = 4,
          control = list(adapt_delta = 0.99))

m4 <- add_waic(m4)
m4 <- add_loo(m4)

save(m4, file = 'models/m4.rda')
```

```{r echo=F}
load('models/m4.rda')
```

What priors did we use?

```{r}
prior_summary(m4)
```

Did the model run well? We should look at diagnostics like Rhat and Neff.

```{r}
print(m4)
```

Diagnostics look good.

# 2. Compare models

WAIC.

```{r}
compare_ic(m1, m2, m3, m4, ic = "waic")
```

LOO.

```{r}
compare_ic(m1, m2, m3, m4, ic = "loo")
```